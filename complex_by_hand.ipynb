{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83bd3d08",
   "metadata": {},
   "source": [
    "# By hand Complex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "abb9eb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option(\"max_colwidth\", None)\n",
    "\n",
    "import pycaret\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pycaret.classification import * \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from functions.homebrew import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA, QuadraticDiscriminantAnalysis as QDA\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "from itertools import combinations\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# If you're using statsmodels or ISLP for specific tasks, keep these imports\n",
    "import statsmodels.api as sm\n",
    "# Assuming ISLP and homebrew are custom modules specific to your project\n",
    "from ISLP import load_data, confusion_table\n",
    "from ISLP.models import ModelSpec as MS, summarize, contrast\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6464e18d",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "86aee0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_transformations(data, cont_cols):\n",
    "    for var in cont_cols:\n",
    "        data[f'log_{var}'] = np.log(data[var] + 1)\n",
    "        data[f'sq_{var}'] = data[var]**2\n",
    "        data[f'sqrt_{var}'] = np.sqrt(data[var])\n",
    "        data[f'inv_{var}'] = 1 / (data[var] + 1)\n",
    "        data[f'boxcox_{var}'], _ = stats.boxcox(data[var] + 1)\n",
    "        data[f'sigmoid_{var}'] = 1 / (1 + np.exp(-data[var]))\n",
    "        data[f'sin_{var}'] = np.sin(data[var])\n",
    "        data[f'cos_{var}'] = np.cos(data[var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "70cd786e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_confusion_matrix(df, name):\n",
    "    \"\"\"\n",
    "    Converts a confusion matrix dataframe into a format with columns for model name, TP, TN, FP, FN.\n",
    "    \n",
    "    Args:\n",
    "    df (pd.DataFrame): Confusion matrix dataframe with multi-index (Truth, Predicted) and columns [0, 1].\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: Reformatted dataframe with model evaluation metrics.\n",
    "    \"\"\"\n",
    "    # Extracting the values from the confusion matrix\n",
    "    tn, fp, fn, tp = df.iloc[0, 0], df.iloc[0, 1], df.iloc[1, 0], df.iloc[1, 1]\n",
    "    acc = (tp + tn) / (tp + tn + fp + fn)\n",
    "    prec = tp / (tp +fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    f1 = 2 * ((prec * recall)/(prec + recall))\n",
    "    # Creating a new dataframe with the desired format\n",
    "    metrics_df = pd.DataFrame({\n",
    "        \"name\": name,\n",
    "        \"tp\": [tp],\n",
    "        \"tn\": [tn],\n",
    "        \"fp\": [fp],\n",
    "        \"fn\": [fn],\n",
    "        'acc': acc,\n",
    "        'prec': prec,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    })\n",
    "    \n",
    "    return metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "54a92b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_results(df):\n",
    "    df = np.where(df == 1, 'Donor','No Donor')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079c3618",
   "metadata": {},
   "source": [
    "# LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1562d311",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/df.csv').drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "712949c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df[df['type'] == 'train'].drop('type',axis =1)\n",
    "dev = df[df['type'] == 'dev'].drop('type',axis =1)\n",
    "test = df[df['type'] == 'test'].drop('type',axis =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a579fc95",
   "metadata": {},
   "source": [
    "# VIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cbcc3bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REMOVED: ['num_child', 'income', 'cos_target_No Donor', 'sin_target_No Donor', 'sigmoid_target_No Donor', 'boxcox_target_No Donor', 'inv_target_No Donor', 'sqrt_target_No Donor', 'sq_target_No Donor', 'cos_zipconvert5_Yes', 'sin_zipconvert5_Yes', 'sigmoid_zipconvert5_Yes', 'boxcox_zipconvert5_Yes', 'inv_zipconvert5_Yes', 'sqrt_zipconvert5_Yes', 'sq_zipconvert5_Yes', 'log_zipconvert5_Yes', 'log_income', 'sq_income', 'log_num_child', 'sq_num_child', 'sigmoid_avg_fam_inc', 'inv_num_child', 'sqrt_months_since_donate', 'sqrt_med_fam_inc', 'sq_wealth', 'boxcox_avg_fam_inc', 'boxcox_num_prom', 'log_last_gift', 'months_since_donate', 'log_avg_gift', 'inv_home_value', 'inv_avg_fam_inc', 'boxcox_time_lag', 'log_wealth', 'inv_med_fam_inc', 'log_largest_gift', 'boxcox_home_value', 'sqrt_num_prom', 'log_lifetime_gifts', 'sqrt_income', 'boxcox_pct_lt15k', 'sqrt_wealth', 'sq_months_since_donate', 'sqrt_avg_fam_inc', 'sqrt_avg_gift', 'boxcox_med_fam_inc', 'sqrt_time_lag', 'boxcox_largest_gift', 'sqrt_pct_lt15k', 'inv_income', 'sqrt_home_value', 'sigmoid_num_child', 'log_num_prom', 'sqrt_last_gift', 'log_months_since_donate', 'boxcox_avg_gift', 'sqrt_lifetime_gifts', 'avg_fam_inc', 'wealth', 'largest_gift', 'med_fam_inc', 'boxcox_last_gift', 'inv_pct_lt15k', 'zipconvert5_Yes', 'num_prom', 'pct_lt15k', 'home_value', 'log_avg_fam_inc', 'inv_wealth', 'log_time_lag', 'boxcox_lifetime_gifts', 'sqrt_num_child', 'avg_gift', 'inv_time_lag', 'log_med_fam_inc', 'boxcox_income', 'inv_largest_gift', 'inv_last_gift', 'sq_avg_fam_inc', 'inv_num_prom', 'last_gift']\n"
     ]
    }
   ],
   "source": [
    "dummies = pd.get_dummies(df, drop_first=True)\n",
    "\n",
    "cat_cols = [\n",
    "    'zipconvert2_Yes', 'zipconvert3_Yes', 'zipconvert4_Yes', 'boxcox_zipconvert5_Yes',\n",
    "    'homeowner_Yes', 'female_Yes', 'type_train', 'type_dev', 'type_test'\n",
    "]\n",
    "\n",
    "cont_cols = [col for col in dummies.columns if col not in cat_cols + ['target']]\n",
    "add_transformations(dummies, cont_cols)\n",
    "\n",
    "kept, removed = remove_high_vif_features(X=dummies.drop('target_No Donor', axis=1), y=dummies['target_No Donor'], vif_threshold=10)\n",
    "print('REMOVED:', removed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f1ce4125",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_vars = list(kept.corr().drop('target')[np.abs(kept.corr()['target'].drop('target')) > .05].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d07a4a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "regress = kept[final_vars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2cf69173",
   "metadata": {},
   "outputs": [],
   "source": [
    "regress['target'] = (df['target'] == 'Donor').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "92d4bae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "kept = kept.drop('log_target_No Donor', axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "602dfca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = kept[regress['type_train'] ==1]\n",
    "dev = kept[(regress['type_test'] == 0) & (regress['type_train'] == 0)]\n",
    "test = kept[regress['type_test'] ==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ea40559b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in [train, dev, test]:\n",
    "    data.drop('type_train', inplace = True, axis = 1)\n",
    "    data.drop('type_test', inplace = True, axis = 1)\n",
    "test = test.drop('target', axis =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05b5e3d",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "67887e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6030dd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting features and target variable for training data\n",
    "X_train = train.drop(['target'], axis =1 )\n",
    "y_train = train['target']\n",
    "X_test = dev.drop(['target'], axis = 1)\n",
    "y_test = dev['target']\n",
    "\n",
    "# Fitting logistic regression model\n",
    "glm = sm.GLM(y_train, X_train, family=sm.families.Binomial())\n",
    "glm = glm.fit()\n",
    "\n",
    "# Summarizing results\n",
    "# print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8a3fe3c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5116666666666667\n"
     ]
    }
   ],
   "source": [
    "log_preds = (glm.predict(X_test) >= 0.5).astype(int)\n",
    "log_acc = accuracy_score(log_preds, y_test)\n",
    "print(log_acc)\n",
    "\n",
    "d = confusion_table(log_preds,y_test)\n",
    "results_df = pd.concat([results_df,convert_confusion_matrix(d, 'Logistic Regression')])\n",
    "\n",
    "log_test_preds = (glm.predict(test) >= 0.5).astype(int)\n",
    "log_test_preds = format_results(log_test_preds)\n",
    "\n",
    "save_df = pd.DataFrame(log_test_preds, columns=['values'])\n",
    "save_df.to_csv('./preds/log.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15de79b1",
   "metadata": {},
   "source": [
    "### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "68a8fce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5066666666666667\n"
     ]
    }
   ],
   "source": [
    "lda = LDA(store_covariance=True)\n",
    "lda.fit(X_train, y_train)\n",
    "\n",
    "lda_preds = lda.predict(X_test)\n",
    "\n",
    "lda_acc = accuracy_score(lda_preds,y_test)\n",
    "print(lda_acc)\n",
    "\n",
    "d = confusion_table(lda_preds,y_test)\n",
    "results_df = pd.concat([results_df,convert_confusion_matrix(d, 'LDA')])\n",
    "\n",
    "\n",
    "lda_test_preds = (lda.predict(test) >= 0.5).astype(int)\n",
    "lda_test_preds = format_results(lda_test_preds)\n",
    "\n",
    "save_df = pd.DataFrame(lda_test_preds, columns=['values'])\n",
    "save_df.to_csv('./preds/lda.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777fb037",
   "metadata": {},
   "source": [
    "# QDA.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a61cd6d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49166666666666664\n"
     ]
    }
   ],
   "source": [
    "qda = QDA(store_covariance=True)\n",
    "qda.fit(X_train, y_train)\n",
    "\n",
    "qda_preds = qda.predict(X_test)\n",
    "\n",
    "qda_acc = accuracy_score(qda_preds,y_test)\n",
    "\n",
    "print(qda_acc)\n",
    "\n",
    "d = confusion_table(qda_preds,y_test)\n",
    "results_df = pd.concat([results_df,convert_confusion_matrix(d, 'QDA')])\n",
    "\n",
    "qda_test_preds = (qda.predict(test) >= 0.5).astype(int)\n",
    "qda_test_preds = format_results(qda_test_preds)\n",
    "\n",
    "save_df = pd.DataFrame(qda_test_preds, columns=['values'])\n",
    "save_df.to_csv('./preds/qda.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7c98b3",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a91d4295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4816666666666667\n"
     ]
    }
   ],
   "source": [
    "knn1 = KNeighborsClassifier(n_neighbors=1)\n",
    "knn1.fit(X_train, y_train)\n",
    "knn1_pred = knn1.predict(X_test)\n",
    "knn1_acc = accuracy_score(knn1_pred,y_test)\n",
    "\n",
    "print(knn1_acc)\n",
    "                         \n",
    "d = confusion_table(knn1_pred, y_test)\n",
    "results_df = pd.concat([results_df,convert_confusion_matrix(d, 'KNN')])\n",
    "\n",
    "knn1_test_preds = (knn1.predict(test) >= 0.5).astype(int)\n",
    "knn1_test_preds = format_results(knn1_test_preds)\n",
    "\n",
    "save_df = pd.DataFrame(knn1_test_preds, columns=['values'])\n",
    "save_df.to_csv('./preds/knn1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f534c6c1",
   "metadata": {},
   "source": [
    "# NB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "944cfc82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.495\n"
     ]
    }
   ],
   "source": [
    "nb = GaussianNB()\n",
    "nb.fit(X_train, y_train)\n",
    "nb_preds = nb.predict(X_test)\n",
    "nb_acc = accuracy_score(nb_preds,y_test)\n",
    "\n",
    "print(nb_acc)\n",
    "save_df = pd.DataFrame(nb_preds, columns=['values'])\n",
    "save_df.to_csv('./preds/nb.csv', index=False)\n",
    "\n",
    "d = confusion_table(nb_preds, y_test)\n",
    "results_df = pd.concat([results_df,convert_confusion_matrix(d, 'Naïve Bayes')])\n",
    "\n",
    "nb_test_preds = (nb.predict(test) >= 0.5).astype(int)\n",
    "nb_test_preds = format_results(nb_test_preds)\n",
    "\n",
    "save_df = pd.DataFrame(nb_test_preds, columns=['values'])\n",
    "save_df.to_csv('./preds/nb.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c885bb83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>tp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>acc</th>\n",
       "      <th>prec</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>159</td>\n",
       "      <td>148</td>\n",
       "      <td>153</td>\n",
       "      <td>140</td>\n",
       "      <td>0.511667</td>\n",
       "      <td>0.509615</td>\n",
       "      <td>0.531773</td>\n",
       "      <td>0.520458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LDA</td>\n",
       "      <td>156</td>\n",
       "      <td>148</td>\n",
       "      <td>156</td>\n",
       "      <td>140</td>\n",
       "      <td>0.506667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.527027</td>\n",
       "      <td>0.513158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>QDA</td>\n",
       "      <td>26</td>\n",
       "      <td>269</td>\n",
       "      <td>286</td>\n",
       "      <td>19</td>\n",
       "      <td>0.491667</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.577778</td>\n",
       "      <td>0.145658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNN</td>\n",
       "      <td>140</td>\n",
       "      <td>149</td>\n",
       "      <td>172</td>\n",
       "      <td>139</td>\n",
       "      <td>0.481667</td>\n",
       "      <td>0.448718</td>\n",
       "      <td>0.501792</td>\n",
       "      <td>0.473773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Naïve Bayes</td>\n",
       "      <td>18</td>\n",
       "      <td>279</td>\n",
       "      <td>294</td>\n",
       "      <td>9</td>\n",
       "      <td>0.495000</td>\n",
       "      <td>0.057692</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.106195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  name   tp   tn   fp   fn       acc      prec    recall  \\\n",
       "0  Logistic Regression  159  148  153  140  0.511667  0.509615  0.531773   \n",
       "0                  LDA  156  148  156  140  0.506667  0.500000  0.527027   \n",
       "0                  QDA   26  269  286   19  0.491667  0.083333  0.577778   \n",
       "0                  KNN  140  149  172  139  0.481667  0.448718  0.501792   \n",
       "0          Naïve Bayes   18  279  294    9  0.495000  0.057692  0.666667   \n",
       "\n",
       "         f1  \n",
       "0  0.520458  \n",
       "0  0.513158  \n",
       "0  0.145658  \n",
       "0  0.473773  \n",
       "0  0.106195  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "765dd04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_acc = {\n",
    "#     'log': 0.5333333,\n",
    "#     'lda': 0.5583333,\n",
    "#     'qda': 0.525,\n",
    "#     'knn':  0.475,\n",
    "#     'nb': 0.5166667,\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3973dcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_df['test_acc'] = test_acc.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "201bfb05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>tp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>acc</th>\n",
       "      <th>prec</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>test_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>159</td>\n",
       "      <td>148</td>\n",
       "      <td>153</td>\n",
       "      <td>140</td>\n",
       "      <td>0.511667</td>\n",
       "      <td>0.509615</td>\n",
       "      <td>0.531773</td>\n",
       "      <td>0.520458</td>\n",
       "      <td>0.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LDA</td>\n",
       "      <td>156</td>\n",
       "      <td>148</td>\n",
       "      <td>156</td>\n",
       "      <td>140</td>\n",
       "      <td>0.506667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.527027</td>\n",
       "      <td>0.513158</td>\n",
       "      <td>0.558333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>QDA</td>\n",
       "      <td>26</td>\n",
       "      <td>269</td>\n",
       "      <td>286</td>\n",
       "      <td>19</td>\n",
       "      <td>0.491667</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.577778</td>\n",
       "      <td>0.145658</td>\n",
       "      <td>0.525000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNN</td>\n",
       "      <td>140</td>\n",
       "      <td>149</td>\n",
       "      <td>172</td>\n",
       "      <td>139</td>\n",
       "      <td>0.481667</td>\n",
       "      <td>0.448718</td>\n",
       "      <td>0.501792</td>\n",
       "      <td>0.473773</td>\n",
       "      <td>0.475000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Naïve Bayes</td>\n",
       "      <td>18</td>\n",
       "      <td>279</td>\n",
       "      <td>294</td>\n",
       "      <td>9</td>\n",
       "      <td>0.495000</td>\n",
       "      <td>0.057692</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.106195</td>\n",
       "      <td>0.516667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  name   tp   tn   fp   fn       acc      prec    recall  \\\n",
       "0  Logistic Regression  159  148  153  140  0.511667  0.509615  0.531773   \n",
       "0                  LDA  156  148  156  140  0.506667  0.500000  0.527027   \n",
       "0                  QDA   26  269  286   19  0.491667  0.083333  0.577778   \n",
       "0                  KNN  140  149  172  139  0.481667  0.448718  0.501792   \n",
       "0          Naïve Bayes   18  279  294    9  0.495000  0.057692  0.666667   \n",
       "\n",
       "         f1  test_acc  \n",
       "0  0.520458  0.533333  \n",
       "0  0.513158  0.558333  \n",
       "0  0.145658  0.525000  \n",
       "0  0.473773  0.475000  \n",
       "0  0.106195  0.516667  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
